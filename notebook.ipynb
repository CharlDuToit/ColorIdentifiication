{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import ipywidgets as widgets\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "from scipy.spatial.distance import cdist\n",
    "HTML('../style/course.css') #apply general CSS\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (imshow, hsv_inrange_mask, crop_image, get_edges_mask, get_files_dict_list, filter_data, select_top_by_class,\n",
    "                    histogram_distances, smallest_distance_label, confusion_matrix_df, create_evaluation_df, largest_occupancy_label, \n",
    "                    focal_spread_mask, mlib_rgb_to_cv2_rgb, hsv_percentile_mask, distances_dict_to_df, print_execution_time,\n",
    "                    ColumnNames,IntermediateColumnNames, plot_hue_sat_val_histograms, plot_images)\n",
    "from predictor import ColorPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "import predictor\n",
    "\n",
    "# Reload the module\n",
    "importlib.reload(utils)\n",
    "importlib.reload(predictor)\n",
    "from utils import *\n",
    "from predictor import ColorPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "## 1) Demonstration of ColorPredictor class\n",
    "\n",
    "Overview of method, adjusting hyperparamters, inference and evaluation\n",
    "\n",
    "## 2) Histograms\n",
    "\n",
    "Mean and standard deviations of histograms for a particular class\n",
    "\n",
    "## 3) The process\n",
    "\n",
    "Visualization of the process and discussion of design decisions\n",
    "\n",
    "## 4) Incorrect predictions\n",
    "\n",
    "Visualizations of incorrect labels\n",
    "\n",
    "## 5) Random hyperparameter search\n",
    "\n",
    "## 6) Some machine learning\n",
    "\n",
    "Using features extracted from the ColorPredictor to enhance predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of ColorPredictor class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class predicts the overall color of objects, in this case, cars.\n",
    "There are two main approaches.\n",
    "The first finds the color with the most occupancy by looking determining all the pixels that lie in the HSV range for a particulare color.\n",
    "This is a fully hard-coded unsupervised method.\n",
    "\n",
    "The second method uses the H, S and V histograms of an image.\n",
    "It requires knowledge of the average and standard deviations of the histograms for each color.\n",
    "It is therefore a supervised method that requires training.\n",
    "The number of saved values that are stored to a file are : n_colors x 3 x n_bins x 2.\n",
    "It compares the histograms on an image to the average histograms of each color, and chooses\n",
    "the most similar color.\n",
    "The average square distance between each bin is normalized by the color std values.\n",
    "\n",
    "The formula is:\n",
    "dist_for_color = sqrt( sum(  ((b_color - b_img)/ b_color_std )**2 )),\n",
    "where the sum is computed over all (b)ins, which usually is 256 * 3 = 768 bins.\n",
    "The standard deviations are also weighted, where each of the 9 colors get 3 weights, one for H S and V.\n",
    "This way we can pay more attention less attention to hue when considering black for example.\n",
    "\n",
    "Another approach would be to research HSV or RGB histograms for e.g. blue objects in general, and then use the same formula as before.\n",
    "This has an advantage, since the average histograms in my method contains background pixels, which is not desired.\n",
    "This way the histograms are not learned from the train set, but hardcoded and should be more robust to new scenarios.\n",
    "However, the general histogram may not apply well to cars.\n",
    "( This is a method I still want to test )\n",
    "\n",
    "\n",
    "For both methods we use the same image processing which consists of cropping, edge detection, saturation and value clipping and focal scaling. These will be explained later.\n",
    "\n",
    "When predicting labels for each image, a label is produced for each method.\n",
    "Both methods are therefore evaluated and are completely independant.\n",
    "This comes with the downside of additional execution time in the case that we are only\n",
    "interested in one method.\n",
    "\n",
    "One feature per method per color is extracted, totaling 18 features per image ( we have 9 colors).\n",
    "Calculating the features takes up most of the execution time.\n",
    "Classifying an image is as simple as selecting the color with the highest/lowest value.\n",
    "Parts of the image are ignored, such as edges, before the features are calculated. \n",
    "\n",
    "The HSV range method gets an overall F1 score of 74% for both test and train set.\n",
    "The histogram  method gets an overall F1 score of 80% for the train set and 72% for the test set.\n",
    "\n",
    "These features can also be fed into other ML classifiers.\n",
    "We see up to an 8% increase in accuracy\n",
    "\n",
    "Lastly, I assumed that the images can have different sizes, so I handle one image at a time.\n",
    "A better way would be to load a batch of e.g. 32 images and process them all together, which should be\n",
    "easy for HSV range checking and numpy methods where we can specify the axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we can edit the hyperparameters of the classifier\n",
    "# Maybe skip reading it for now and come back to it later\n",
    "# Can perform a grid search to choose better hyper parameters\n",
    "\n",
    "# These ranges were found by looking at histograms of images, they can definitely be improved\n",
    "ColorPredictor.hsv_ranges = hsv_ranges = {\n",
    "       'black': [[0, 0, 0], [255, 255, 50]], \n",
    "       'blue': [[140, 50, 50], [180, 255, 255]],\n",
    "       'brown': [[10, 25, 25], [30, 255, 255]],\n",
    "       'green': [[55, 25, 25], [140, 255, 255]],\n",
    "       'pink': [[180, 25, 50], [245, 255, 255]], \n",
    "       'red': [[245, 50, 50], [10, 255, 255]],\n",
    "       'silver': [[110, 0, 75], [180, 100, 220]], \n",
    "       'white': [[0, 0, 200], [255, 50, 255]],\n",
    "       'yellow': [[30, 50, 50], [55, 255, 255]]}\n",
    "for key in hsv_ranges.keys():\n",
    "    hsv_ranges[key] = np.array(list(hsv_ranges[key])) / 255.0\n",
    "    \n",
    "# A weight for H, S and V for each color\n",
    "ColorPredictor.hsv_color_weights = {'black': np.array([1.2, 0.8, 1.2]),\n",
    "                                    'blue': np.array([0.8, 0.9, 1. ]),\n",
    "                                    'brown': np.array([1. , 1.1, 1.1]),\n",
    "                                    'green': np.array([0.8, 0.9, 1. ]),\n",
    "                                    'pink': np.array([1.1, 1. , 1. ]), \n",
    "                                    'red': np.array([1. , 0.9, 0.9]),\n",
    "                                    'silver': np.array([1. , 1.2, 0.9]),\n",
    "                                    'white': np.array([0.8, 0.9, 1.2]),\n",
    "                                    'yellow': np.array([0.8, 1.1, 1. ])}\n",
    "\n",
    "\n",
    "ColorPredictor.focal_spread_min_val = 0.1 # pixels get weighted with distance to the center, with the furthest pixel having 0.1\n",
    "ColorPredictor.sat_percentile_min = 8 # all pixels with a saturation lower than the 8th percentile are ignored\n",
    "ColorPredictor.val_percentile_min = 8 # all pixels with a value lower than the 8th percentile are ignored\n",
    "ColorPredictor.edges_val = 160 # used by cv2.canny\n",
    "ColorPredictor.edges_blur_ksize = 3 # blurs edges with kernel of size 3\n",
    "ColorPredictor.crop_ratio = 0.07 # cars are usually in the center of image\n",
    "ColorPredictor.bins = 256 # number of bins for histograms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable?:  True  trained?:  True  training queued?:  False\n",
      "Execution time for 'process_files': 191.438541 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"     Loads a list of dictionaries containing file paths, and true labels if available.\n",
    "        Checks whether the average histograms of each color should be calculated for inference later i.e. should\n",
    "        the model be trained? Also tries to load these weights from a file. \n",
    "        Processes each file by extracting some features for each image ( The bulk of execution time).\n",
    "        Lastly performs training if user has requested it and labeled data is available.\n",
    "        Training is really quick since it just calculating an average and std for each color for each channel.\n",
    "        So we have  3 x 256 x 2 trained values for each color)\"\"\"\n",
    "\n",
    "# Set top = 0 to evaluate the full dataset. \n",
    "top = 10\n",
    "\n",
    "# save_intermediate_images = True is only for demonstration, debugging and development\n",
    "\n",
    "# The contructor will generate the features for each image, this part takes the longest, 70 sec for entire dataset\n",
    "# 190 seconds if  save_intermediate_images = True\n",
    "clr_predictor = ColorPredictor(Path('./dataset'),\n",
    "                               Path('./'),\n",
    "                               train_if_not_trained=True,\n",
    "                               train_regardless=False, # set this to true to retrain \n",
    "                               top=top, \n",
    "                               save_intermediate_images = True\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we created a dataframe containing labels for both methods. \n",
    "Then we evaluate it, giving two evaluation dataframes per method.\n",
    "One for a confusion matrix, another for F1, recall and precision scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for 'infer': 3.377001 seconds\n"
     ]
    }
   ],
   "source": [
    "# \"Infers by looking at smallest distance for histograms, and largest occupancy rate for HSV ranges\n",
    "# This df contains the train set, test set and unlabeled images.\n",
    "# During evaluation we seperate the train set from the test set and ignore the unlabeled images. \n",
    "df_inferred = clr_predictor.infer(save_to_file=False)\n",
    "\n",
    "\"\"\"     Calculates the confusion matrix and saves to file. \n",
    "        Calculates precision, recall and F1 score for each class and saves to file.\n",
    "        Seperate files are stored for the train and test set.\n",
    "        Seperate files are stored for the HSV range method and histogram method.\n",
    "        \"\"\"\n",
    "eval_dfs, eval_dfs_names = clr_predictor.evaluate(df_inferred, save_to_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>true_color</th>\n",
       "      <th>dataset</th>\n",
       "      <th>black_occupancy</th>\n",
       "      <th>blue_occupancy</th>\n",
       "      <th>brown_occupancy</th>\n",
       "      <th>green_occupancy</th>\n",
       "      <th>pink_occupancy</th>\n",
       "      <th>red_occupancy</th>\n",
       "      <th>silver_occupancy</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_hist_color</th>\n",
       "      <th>black_dist</th>\n",
       "      <th>blue_dist</th>\n",
       "      <th>brown_dist</th>\n",
       "      <th>green_dist</th>\n",
       "      <th>pink_dist</th>\n",
       "      <th>red_dist</th>\n",
       "      <th>silver_dist</th>\n",
       "      <th>white_dist</th>\n",
       "      <th>yellow_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset\\train\\black\\2289261.jpg</td>\n",
       "      <td>black</td>\n",
       "      <td>train</td>\n",
       "      <td>0.614714</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.326741</td>\n",
       "      <td>...</td>\n",
       "      <td>black</td>\n",
       "      <td>23.851600</td>\n",
       "      <td>66.417659</td>\n",
       "      <td>159.665521</td>\n",
       "      <td>187.454093</td>\n",
       "      <td>122.282122</td>\n",
       "      <td>191.222392</td>\n",
       "      <td>44.306277</td>\n",
       "      <td>57.642947</td>\n",
       "      <td>194.325317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset\\train\\black\\2289271.jpg</td>\n",
       "      <td>black</td>\n",
       "      <td>train</td>\n",
       "      <td>0.408058</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.293821</td>\n",
       "      <td>...</td>\n",
       "      <td>black</td>\n",
       "      <td>14.655955</td>\n",
       "      <td>24.226095</td>\n",
       "      <td>26.512584</td>\n",
       "      <td>34.493292</td>\n",
       "      <td>30.980882</td>\n",
       "      <td>44.065179</td>\n",
       "      <td>16.927640</td>\n",
       "      <td>18.325853</td>\n",
       "      <td>35.509598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset\\train\\black\\2429402.jpg</td>\n",
       "      <td>black</td>\n",
       "      <td>train</td>\n",
       "      <td>0.619234</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.222249</td>\n",
       "      <td>0.030295</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.082401</td>\n",
       "      <td>...</td>\n",
       "      <td>black</td>\n",
       "      <td>20.443563</td>\n",
       "      <td>46.937965</td>\n",
       "      <td>32.425545</td>\n",
       "      <td>53.332836</td>\n",
       "      <td>36.826812</td>\n",
       "      <td>62.490569</td>\n",
       "      <td>33.483860</td>\n",
       "      <td>45.665926</td>\n",
       "      <td>58.869159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset\\train\\black\\257213_share1.jpg</td>\n",
       "      <td>black</td>\n",
       "      <td>train</td>\n",
       "      <td>0.588055</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>...</td>\n",
       "      <td>black</td>\n",
       "      <td>24.750873</td>\n",
       "      <td>53.997414</td>\n",
       "      <td>119.552524</td>\n",
       "      <td>42.050988</td>\n",
       "      <td>155.754956</td>\n",
       "      <td>156.347114</td>\n",
       "      <td>42.056981</td>\n",
       "      <td>47.858057</td>\n",
       "      <td>91.104464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset\\train\\black\\26188161.jpg</td>\n",
       "      <td>black</td>\n",
       "      <td>train</td>\n",
       "      <td>0.510914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.146159</td>\n",
       "      <td>...</td>\n",
       "      <td>black</td>\n",
       "      <td>18.028144</td>\n",
       "      <td>35.040003</td>\n",
       "      <td>27.872283</td>\n",
       "      <td>35.908789</td>\n",
       "      <td>36.239849</td>\n",
       "      <td>95.283291</td>\n",
       "      <td>25.397878</td>\n",
       "      <td>30.416170</td>\n",
       "      <td>41.826449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>dataset\\test\\yellow\\eorg7m1z49bnggxvjyrqi54t31...</td>\n",
       "      <td>yellow</td>\n",
       "      <td>test</td>\n",
       "      <td>0.071137</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.806029</td>\n",
       "      <td>0.062081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073378</td>\n",
       "      <td>...</td>\n",
       "      <td>yellow</td>\n",
       "      <td>63.043876</td>\n",
       "      <td>36.777931</td>\n",
       "      <td>49.817238</td>\n",
       "      <td>57.213382</td>\n",
       "      <td>67.592393</td>\n",
       "      <td>56.668988</td>\n",
       "      <td>115.082469</td>\n",
       "      <td>87.472430</td>\n",
       "      <td>28.834948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>dataset\\test\\yellow\\es_gl000336923_11.jpg</td>\n",
       "      <td>yellow</td>\n",
       "      <td>test</td>\n",
       "      <td>0.170140</td>\n",
       "      <td>0.244442</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>...</td>\n",
       "      <td>blue</td>\n",
       "      <td>126.652933</td>\n",
       "      <td>30.961796</td>\n",
       "      <td>82.563858</td>\n",
       "      <td>36.019303</td>\n",
       "      <td>68.318435</td>\n",
       "      <td>51.557655</td>\n",
       "      <td>105.290807</td>\n",
       "      <td>93.449041</td>\n",
       "      <td>33.023889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>dataset\\test\\yellow\\es_gl000480512qhs6661_0011...</td>\n",
       "      <td>yellow</td>\n",
       "      <td>test</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010280</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>...</td>\n",
       "      <td>yellow</td>\n",
       "      <td>206.805944</td>\n",
       "      <td>75.609858</td>\n",
       "      <td>166.280388</td>\n",
       "      <td>83.998520</td>\n",
       "      <td>216.549524</td>\n",
       "      <td>74.621712</td>\n",
       "      <td>164.271436</td>\n",
       "      <td>163.347478</td>\n",
       "      <td>32.705319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>dataset\\test\\yellow\\everyone-is-asking-for1.jpg</td>\n",
       "      <td>yellow</td>\n",
       "      <td>test</td>\n",
       "      <td>0.082527</td>\n",
       "      <td>0.078564</td>\n",
       "      <td>0.014231</td>\n",
       "      <td>0.017108</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.014084</td>\n",
       "      <td>...</td>\n",
       "      <td>yellow</td>\n",
       "      <td>309.485273</td>\n",
       "      <td>55.221919</td>\n",
       "      <td>116.898694</td>\n",
       "      <td>55.288016</td>\n",
       "      <td>78.938083</td>\n",
       "      <td>93.045223</td>\n",
       "      <td>248.635900</td>\n",
       "      <td>295.409480</td>\n",
       "      <td>21.201528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>dataset\\test\\yellow\\f1xtg5ecjdmt5unwnen5xjdh81...</td>\n",
       "      <td>yellow</td>\n",
       "      <td>test</td>\n",
       "      <td>0.223576</td>\n",
       "      <td>0.072438</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.060036</td>\n",
       "      <td>...</td>\n",
       "      <td>yellow</td>\n",
       "      <td>91.389647</td>\n",
       "      <td>46.348388</td>\n",
       "      <td>74.150560</td>\n",
       "      <td>47.823699</td>\n",
       "      <td>95.266975</td>\n",
       "      <td>62.419798</td>\n",
       "      <td>71.170716</td>\n",
       "      <td>72.437566</td>\n",
       "      <td>21.593291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3509 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   file true_color dataset  \\\n",
       "0                       dataset\\train\\black\\2289261.jpg      black   train   \n",
       "1                       dataset\\train\\black\\2289271.jpg      black   train   \n",
       "2                       dataset\\train\\black\\2429402.jpg      black   train   \n",
       "3                 dataset\\train\\black\\257213_share1.jpg      black   train   \n",
       "4                      dataset\\train\\black\\26188161.jpg      black   train   \n",
       "...                                                 ...        ...     ...   \n",
       "3504  dataset\\test\\yellow\\eorg7m1z49bnggxvjyrqi54t31...     yellow    test   \n",
       "3505          dataset\\test\\yellow\\es_gl000336923_11.jpg     yellow    test   \n",
       "3506  dataset\\test\\yellow\\es_gl000480512qhs6661_0011...     yellow    test   \n",
       "3507    dataset\\test\\yellow\\everyone-is-asking-for1.jpg     yellow    test   \n",
       "3508  dataset\\test\\yellow\\f1xtg5ecjdmt5unwnen5xjdh81...     yellow    test   \n",
       "\n",
       "      black_occupancy  blue_occupancy  brown_occupancy  green_occupancy  \\\n",
       "0            0.614714        0.000109         0.000000         0.000122   \n",
       "1            0.408058        0.002289         0.000714         0.006826   \n",
       "2            0.619234        0.083900         0.222249         0.030295   \n",
       "3            0.588055        0.004377         0.002878         0.009587   \n",
       "4            0.510914        0.000000         0.000015         0.000151   \n",
       "...               ...             ...              ...              ...   \n",
       "3504         0.071137        0.001722         0.806029         0.062081   \n",
       "3505         0.170140        0.244442         0.005077         0.008224   \n",
       "3506         0.000000        0.000000         0.010280         0.000299   \n",
       "3507         0.082527        0.078564         0.014231         0.017108   \n",
       "3508         0.223576        0.072438         0.000946         0.004980   \n",
       "\n",
       "      pink_occupancy  red_occupancy  silver_occupancy  ...  pred_hist_color  \\\n",
       "0           0.000058       0.000057          0.326741  ...            black   \n",
       "1           0.003818       0.000484          0.293821  ...            black   \n",
       "2           0.006690       0.004751          0.082401  ...            black   \n",
       "3           0.000000       0.000000          0.006056  ...            black   \n",
       "4           0.000011       0.000330          0.146159  ...            black   \n",
       "...              ...            ...               ...  ...              ...   \n",
       "3504        0.000000       0.000000          0.073378  ...           yellow   \n",
       "3505        0.000448       0.000000          0.013954  ...             blue   \n",
       "3506        0.003101       0.000000          0.006583  ...           yellow   \n",
       "3507        0.001748       0.000344          0.014084  ...           yellow   \n",
       "3508        0.005177       0.003761          0.060036  ...           yellow   \n",
       "\n",
       "      black_dist  blue_dist  brown_dist  green_dist   pink_dist    red_dist  \\\n",
       "0      23.851600  66.417659  159.665521  187.454093  122.282122  191.222392   \n",
       "1      14.655955  24.226095   26.512584   34.493292   30.980882   44.065179   \n",
       "2      20.443563  46.937965   32.425545   53.332836   36.826812   62.490569   \n",
       "3      24.750873  53.997414  119.552524   42.050988  155.754956  156.347114   \n",
       "4      18.028144  35.040003   27.872283   35.908789   36.239849   95.283291   \n",
       "...          ...        ...         ...         ...         ...         ...   \n",
       "3504   63.043876  36.777931   49.817238   57.213382   67.592393   56.668988   \n",
       "3505  126.652933  30.961796   82.563858   36.019303   68.318435   51.557655   \n",
       "3506  206.805944  75.609858  166.280388   83.998520  216.549524   74.621712   \n",
       "3507  309.485273  55.221919  116.898694   55.288016   78.938083   93.045223   \n",
       "3508   91.389647  46.348388   74.150560   47.823699   95.266975   62.419798   \n",
       "\n",
       "      silver_dist  white_dist  yellow_dist  \n",
       "0       44.306277   57.642947   194.325317  \n",
       "1       16.927640   18.325853    35.509598  \n",
       "2       33.483860   45.665926    58.869159  \n",
       "3       42.056981   47.858057    91.104464  \n",
       "4       25.397878   30.416170    41.826449  \n",
       "...           ...         ...          ...  \n",
       "3504   115.082469   87.472430    28.834948  \n",
       "3505   105.290807   93.449041    33.023889  \n",
       "3506   164.271436  163.347478    32.705319  \n",
       "3507   248.635900  295.409480    21.201528  \n",
       "3508    71.170716   72.437566    21.593291  \n",
       "\n",
       "[3509 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at how we store the predictions and some of the color features\n",
    "df_demo = df_inferred\n",
    "if clr_predictor.save_intermediate_images:\n",
    "    df_demo = df_demo.drop(columns=ColorPredictor.intermediate_columns_to_drop())\n",
    "\n",
    "# we have 9 colors\n",
    "# 23 columns = file + true_color + dataset + hist method label + occupancy method label\n",
    "#           9 * color occupancy + 9 * color hist\n",
    "# \n",
    "# print(df_demo)\n",
    "df_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file                                                   dataset\\train\\black\\2289261.jpg\n",
       "true_color                                                                       black\n",
       "dataset                                                                          train\n",
       "black_occupancy                                                               0.614714\n",
       "blue_occupancy                                                             0.000108969\n",
       "brown_occupancy                                                                      0\n",
       "green_occupancy                                                            0.000122182\n",
       "pink_occupancy                                                             5.77665e-05\n",
       "red_occupancy                                                              5.73425e-05\n",
       "silver_occupancy                                                              0.326741\n",
       "white_occupancy                                                             0.00466734\n",
       "yellow_occupancy                                                           0.000141316\n",
       "original                             [[[0.06274509803921569, 0.058823529411764705, ...\n",
       "cropped                              [[[0.12941176470588237, 0.12549019607843137, 0...\n",
       "edges_mask                           [[True, True, True, True, True, True, True, Tr...\n",
       "sv_mask                              [[True, True, True, True, True, True, True, Tr...\n",
       "focal_mask                           [[0.09999999999999998, 0.1046752291416817, 0.1...\n",
       "mask                                 [[True, True, True, True, True, True, True, Tr...\n",
       "total_mask                           [[0.09999999999999998, 0.1046752291416817, 0.1...\n",
       "black_mask_full                      [[True, True, True, True, True, True, True, Tr...\n",
       "black_mask                           [[0.09999999999999998, 0.1046752291416817, 0.1...\n",
       "blue_mask_full                       [[False, False, False, False, False, False, Fa...\n",
       "blue_mask                            [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "brown_mask_full                      [[False, False, False, False, False, False, Fa...\n",
       "brown_mask                           [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "green_mask_full                      [[False, False, False, False, False, False, Fa...\n",
       "green_mask                           [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "pink_mask_full                       [[False, False, False, False, False, False, Fa...\n",
       "pink_mask                            [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "red_mask_full                        [[False, False, False, False, False, False, Fa...\n",
       "red_mask                             [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "silver_mask_full                     [[False, False, False, False, False, False, Fa...\n",
       "silver_mask                          [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "white_mask_full                      [[False, False, False, False, False, False, Fa...\n",
       "white_mask                           [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "yellow_mask_full                     [[False, False, False, False, False, False, Fa...\n",
       "yellow_mask                          [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "val_histogram_before_equalization    ([4.254181320303901, 23.154017557518323, 9.697...\n",
       "val_histogram                        [37.9857989484194, 0.0, 0.0, 0.0, 0.0, 0.0, 0....\n",
       "sat_histogram                        [45.15339049749389, 0.14846112422849095, 0.222...\n",
       "hue_histogram                        [46.809134267214596, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "pred_occupancy_color                                                             black\n",
       "pred_hist_color                                                                  black\n",
       "black_dist                                                                     23.8516\n",
       "blue_dist                                                                      66.4177\n",
       "brown_dist                                                                     159.666\n",
       "green_dist                                                                     187.454\n",
       "pink_dist                                                                      122.282\n",
       "red_dist                                                                       191.222\n",
       "silver_dist                                                                    44.3063\n",
       "white_dist                                                                     57.6429\n",
       "yellow_dist                                                                    194.325\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at what is stored in one row.\n",
    "# We will visuale the masks shortly\n",
    "df_inferred.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_occupancy_scores.csv \n",
      " --------------------------------\n",
      "                 black  blue  brown  green  pink  red  silver  white  yellow  \\\n",
      "black              338    32      7      5     0    0      41      8       0   \n",
      "blue                23   384      0     31     0    0       5      0       0   \n",
      "brown               38     2    108      0     1   12       6      3       0   \n",
      "green               10     0      1    118     0    0       1      0      24   \n",
      "pink                25     3      3      1   297   66      10     19       0   \n",
      "red                 22     3      2      0     6  358       3      1       0   \n",
      "silver              27    13      8      2     0    0     127     39       1   \n",
      "white               20     2      9      1     0    0      72    205       1   \n",
      "yellow               9     0     75      0     0    0       2      3     214   \n",
      "Total Predicted    512   439    213    158   304  436     267    278     240   \n",
      "\n",
      "                 Total True  \n",
      "black                 431.0  \n",
      "blue                  443.0  \n",
      "brown                 170.0  \n",
      "green                 154.0  \n",
      "pink                  424.0  \n",
      "red                   395.0  \n",
      "silver                217.0  \n",
      "white                 310.0  \n",
      "yellow                303.0  \n",
      "Total Predicted         NaN  \n",
      "--------------------------------\n",
      "train_occupancy_scores.csv \n",
      " --------------------------------\n",
      "           Precision    Recall  F1-score  Overall\n",
      "black       0.660156  0.784223  0.716861      NaN\n",
      "blue        0.874715  0.866817  0.870748      NaN\n",
      "brown       0.507042  0.635294  0.563969      NaN\n",
      "green       0.746835  0.766234  0.756410      NaN\n",
      "pink        0.976974  0.700472  0.815934      NaN\n",
      "red         0.821101  0.906329  0.861613      NaN\n",
      "silver      0.475655  0.585253  0.524793      NaN\n",
      "white       0.737410  0.661290  0.697279      NaN\n",
      "yellow      0.891667  0.706271  0.788214      NaN\n",
      "Precision        NaN       NaN       NaN  0.75483\n",
      "Recall           NaN       NaN       NaN  0.75483\n",
      "F1-score         NaN       NaN       NaN  0.75483\n",
      "--------------------------------\n",
      "train_hist_conf_matrix.csv \n",
      " --------------------------------\n",
      "                 black  blue  brown  green  pink  red  silver  white  yellow  \\\n",
      "black              380    10     12      4     3    0      16      6       0   \n",
      "blue                28   392      7      6     7    1       0      1       1   \n",
      "brown               21     0    116      4    19    0       4      2       4   \n",
      "green                3     3      2    143     0    0       2      0       1   \n",
      "pink                 6     1      3      1   402    4       6      1       0   \n",
      "red                  1     0     10      0   116  268       0      0       0   \n",
      "silver              66     7      5      5     3    0     107     24       0   \n",
      "white               35     2      5      9    10    0      35    212       2   \n",
      "yellow               2     9      1      4     0    1       1      0     285   \n",
      "Total Predicted    542   424    161    176   560  274     171    246     293   \n",
      "\n",
      "                 Total True  \n",
      "black                 431.0  \n",
      "blue                  443.0  \n",
      "brown                 170.0  \n",
      "green                 154.0  \n",
      "pink                  424.0  \n",
      "red                   395.0  \n",
      "silver                217.0  \n",
      "white                 310.0  \n",
      "yellow                303.0  \n",
      "Total Predicted         NaN  \n",
      "--------------------------------\n",
      "train_hist_scores.csv \n",
      " --------------------------------\n",
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.701107  0.881671  0.781089       NaN\n",
      "blue        0.924528  0.884876  0.904268       NaN\n",
      "brown       0.720497  0.682353  0.700906       NaN\n",
      "green       0.812500  0.928571  0.866667       NaN\n",
      "pink        0.717857  0.948113  0.817073       NaN\n",
      "red         0.978102  0.678481  0.801196       NaN\n",
      "silver      0.625731  0.493088  0.551546       NaN\n",
      "white       0.861789  0.683871  0.762590       NaN\n",
      "yellow      0.972696  0.940594  0.956376       NaN\n",
      "Precision        NaN       NaN       NaN  0.809624\n",
      "Recall           NaN       NaN       NaN  0.809624\n",
      "F1-score         NaN       NaN       NaN  0.809624\n",
      "--------------------------------\n",
      "test_occupancy_scores.csv \n",
      " --------------------------------\n",
      "                 black  blue  brown  green  pink  red  silver  white  yellow  \\\n",
      "black               82     7      0      3     0    0       4      2       0   \n",
      "blue                 5    84      1      8     0    0       1      1       0   \n",
      "brown               13     1     17      0     0    3       3      3       0   \n",
      "green                1     0      0     29     0    0       0      0       5   \n",
      "pink                 6     2      3      1    83    4       0      1       0   \n",
      "red                  5     0      0      0     2   90       0      3       0   \n",
      "silver               3     1      5      1     0    0      21      9       0   \n",
      "white                7     2      0      0     0    0      15     25       0   \n",
      "yellow               0     0     22      0     0    0       0      1      77   \n",
      "Total Predicted    122    97     48     42    85   97      44     45      82   \n",
      "\n",
      "                 Total True  \n",
      "black                  98.0  \n",
      "blue                  100.0  \n",
      "brown                  40.0  \n",
      "green                  35.0  \n",
      "pink                  100.0  \n",
      "red                   100.0  \n",
      "silver                 40.0  \n",
      "white                  49.0  \n",
      "yellow                100.0  \n",
      "Total Predicted         NaN  \n",
      "--------------------------------\n",
      "test_occupancy_scores.csv \n",
      " --------------------------------\n",
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.672131  0.836735  0.745455       NaN\n",
      "blue        0.865979  0.840000  0.852792       NaN\n",
      "brown       0.354167  0.425000  0.386364       NaN\n",
      "green       0.690476  0.828571  0.753247       NaN\n",
      "pink        0.976471  0.830000  0.897297       NaN\n",
      "red         0.927835  0.900000  0.913706       NaN\n",
      "silver      0.477273  0.525000  0.500000       NaN\n",
      "white       0.555556  0.510204  0.531915       NaN\n",
      "yellow      0.939024  0.770000  0.846154       NaN\n",
      "Precision        NaN       NaN       NaN  0.767372\n",
      "Recall           NaN       NaN       NaN  0.767372\n",
      "F1-score         NaN       NaN       NaN  0.767372\n",
      "--------------------------------\n",
      "test_hist_conf_matrix.csv \n",
      " --------------------------------\n",
      "                 black  blue  brown  green  pink  red  silver  white  yellow  \\\n",
      "black               78     3      2      4     1    0       6      4       0   \n",
      "blue                12    76      1      0     9    0       1      1       0   \n",
      "brown               12     0     19      0     6    1       1      0       1   \n",
      "green                4     2      1     25     1    0       1      0       1   \n",
      "pink                 2     0      5      0    89    2       2      0       0   \n",
      "red                  0     0      0      0    35   65       0      0       0   \n",
      "silver               9     1      3      1     0    0      13     13       0   \n",
      "white                9     2      0      2     2    0       9     24       1   \n",
      "yellow               0     6      0      3     0    0       2      0      89   \n",
      "Total Predicted    126    90     31     35   143   68      35     42      92   \n",
      "\n",
      "                 Total True  \n",
      "black                  98.0  \n",
      "blue                  100.0  \n",
      "brown                  40.0  \n",
      "green                  35.0  \n",
      "pink                  100.0  \n",
      "red                   100.0  \n",
      "silver                 40.0  \n",
      "white                  49.0  \n",
      "yellow                100.0  \n",
      "Total Predicted         NaN  \n",
      "--------------------------------\n",
      "test_hist_scores.csv \n",
      " --------------------------------\n",
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.619048  0.795918  0.696429       NaN\n",
      "blue        0.844444  0.760000  0.800000       NaN\n",
      "brown       0.612903  0.475000  0.535211       NaN\n",
      "green       0.714286  0.714286  0.714286       NaN\n",
      "pink        0.622378  0.890000  0.732510       NaN\n",
      "red         0.955882  0.650000  0.773810       NaN\n",
      "silver      0.371429  0.325000  0.346667       NaN\n",
      "white       0.571429  0.489796  0.527473       NaN\n",
      "yellow      0.967391  0.890000  0.927083       NaN\n",
      "Precision        NaN       NaN       NaN  0.722054\n",
      "Recall           NaN       NaN       NaN  0.722054\n",
      "F1-score         NaN       NaN       NaN  0.722054\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "for eval_df, eval_df_name in zip(eval_dfs, eval_dfs_names):\n",
    "    print(eval_df_name, '\\n --------------------------------')\n",
    "    print(eval_df)\n",
    "    print('--------------------------------')\n",
    "\n",
    "#  We see that the occupancy method is consistent for the train and test set\n",
    "#      F1 scores\n",
    "#       Hist       Occupancy\n",
    "#Train  0.809624   0.75483\n",
    "#Test   0.722054   0.767372"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and standard deviation of each histogram of each color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0803a5abaac440eb9ff094e6733bbb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='Color:', index=5, options=('black', 'blue', 'brown', 'green…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_color_histograms(color)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a slider widget with the color names as options\n",
    "hist_color_slider = widgets.SelectionSlider(options=ColorPredictor.color_names,\n",
    "                                 value='red',\n",
    "                                 description='Color:')\n",
    "\n",
    "\n",
    "# Define a function to plot the selected color as a rectangle\n",
    "def plot_color_histograms(color):\n",
    "    means = clr_predictor.hsv_hist_means_stds['means'][color]\n",
    "    stds = clr_predictor.hsv_hist_means_stds['stds'][color]\n",
    "    plot_hue_sat_val_histograms(means[0], means[1], means[2], title='Mean Histogram')\n",
    "    plot_hue_sat_val_histograms(stds[0], stds[1], stds[2], title='Standard Deviation Histograms')\n",
    "    \n",
    "\n",
    "# Use the interact function to link the slider and the plot function\n",
    "widgets.interact(plot_color_histograms, color=hist_color_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the process\n",
    "\n",
    "The process_image(img) method extracts image features such as histograms and color occupancy.\n",
    "3 histograms are calculated, one for H, S and V channels.\n",
    "A mask according to each color is geneerated using the hard-coded hsv_ranges.\n",
    "The weighted average of the mask determines the occupancy of that color.\n",
    "\n",
    "These features can be used however desired in a later stage.\n",
    "In this case, the average histogram for each color is used to\n",
    "determine the similarity of the image histograms with each color.\n",
    "This average is obtained during training from the train set, as visualed earlier. \n",
    "\n",
    "The pixels with the lowest saturation and value are ignored, since most cars\n",
    "have some black and white pixels due to reflections, the car outline;\n",
    "and very dark regions such as shadows, wheels.\n",
    "\n",
    "Edges are also ignored, since these tend to be wheels as well as other things\n",
    "such as mirrors, the grid at the front of the car, the inside of the car.\n",
    "The edges are also blurred to increase the number of ignored pixels.\n",
    "\n",
    "\n",
    "Since most cars take up almost the whole image, we use focal scaling, where\n",
    "pixels further from the center have a lower weight.\n",
    "We use a linear scale, where the pixel furthest away has a weight of 0.1\n",
    "The image is also cropped for the same reason.\n",
    "\n",
    "We combine the masks from focal scaling, edges and sat_val clipping.\n",
    "\n",
    "Please see predictor.ColorPredictor.process_image(self, img) for the implementation details\n",
    "\n",
    "In the code below we can see how the difference between the black mask and full black mask\n",
    "sucessfully gave less weight to black pixels in the wheels. The same is true for white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ab76a91de9410ab193c03e8ce9989b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='Color:', index=5, options=('black', 'blue', 'brown', 'green…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.showcase_image(color_name, index)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a slider widget with the color names as options\n",
    "color_slider = widgets.SelectionSlider(options=ColorPredictor.color_names,\n",
    "                                 value='red',\n",
    "                                 description='Color:')\n",
    "\n",
    "file_slider = widgets.SelectionSlider(options=np.arange(top if top > 0 else 100),\n",
    "                                      value=0,\n",
    "                                      description='File:')\n",
    "\n",
    "\n",
    "def showcase_image(color_name, index):\n",
    "    \n",
    "    \n",
    "    color_df = filter_data(df_inferred, {ColumnNames.true_label : color_name})\n",
    "    row = color_df.iloc[index]\n",
    "    \n",
    "    true_color = row[ColumnNames.true_label]\n",
    "    pred_hist_label = row[ColumnNames.pred_hist_color]\n",
    "    pred_occupancy_label = row[ColumnNames.pred_occupancy_color]\n",
    "    print(f'True color: {true_color}, Histogram Label: {pred_hist_label}, Occupncy Label: {pred_occupancy_label}')\n",
    "    \n",
    "    # Preprocessing\n",
    "\n",
    "    images_column_names = [\n",
    "        IntermediateColumnNames.original,\n",
    "        IntermediateColumnNames.cropped,\n",
    "        IntermediateColumnNames.sv_mask,\n",
    "        IntermediateColumnNames.edges_mask,\n",
    "        IntermediateColumnNames.mask,\n",
    "        IntermediateColumnNames.total_mask\n",
    "    ]\n",
    "    images_kwargs = {}\n",
    "    for column in images_column_names:\n",
    "        images_kwargs[column] = row[column]\n",
    "\n",
    "    plot_images(n_columns=3, **images_kwargs)\n",
    "    \n",
    "    # Histograms\n",
    "    \n",
    "    plot_hue_sat_val_histograms(row[IntermediateColumnNames.hue_histogram],\n",
    "                                row[IntermediateColumnNames.sat_histogram],\n",
    "                                row[IntermediateColumnNames.val_histogram],\n",
    "                                title='HSV Histogram')\n",
    "    \n",
    "    # Color masks\n",
    "    \n",
    "    images_column_names = [f'{col}_mask' for col in ColorPredictor.color_names]\n",
    "    images_column_names += [f'{col}_mask_full' for col in ColorPredictor.color_names]\n",
    "    images_kwargs = {}\n",
    "    for column in images_column_names:\n",
    "        images_kwargs[column] = row[column]\n",
    "        \n",
    "    \n",
    "    plot_images(n_columns=6, **images_kwargs)\n",
    "\n",
    "\n",
    "widgets.interact(showcase_image, color_name=color_slider, index=file_slider)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus on incorrect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96651492ea33400cb85bcadd42f83cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='File:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.showcase_mislabeling(index)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Histogram mistakes\n",
    "#df_mistakes = df[df[ColumnNames.true_label] != df[ColumnNames.pred_hist_color]]\n",
    "\n",
    "# Occupancy mistakes\n",
    "df_mistakes = df_inferred[df_inferred[ColumnNames.true_label] != df_inferred[ColumnNames.pred_occupancy_color]]\n",
    "\n",
    "file_slider_mitakes = widgets.SelectionSlider(options=np.arange(len(df_mistakes)),\n",
    "                                      value=0,\n",
    "                                      description='File:')\n",
    "\n",
    "\n",
    "def showcase_mislabeling(index):\n",
    "    \n",
    "    \n",
    "    row = df_mistakes.iloc[index]\n",
    "    \n",
    "    true_color = row[ColumnNames.true_label]\n",
    "    pred_hist_label = row[ColumnNames.pred_hist_color]\n",
    "    pred_occupancy_label = row[ColumnNames.pred_occupancy_color]\n",
    "    print(f'True color: {true_color}, Histogram Label: {pred_hist_label}, Occupncy Label: {pred_occupancy_label}')\n",
    "    \n",
    "    # Preprocessing\n",
    "\n",
    "    images_column_names = [\n",
    "        #IntermediateColumnNames.original,\n",
    "        IntermediateColumnNames.cropped,\n",
    "        #IntermediateColumnNames.sv_mask,\n",
    "        IntermediateColumnNames.edges_mask,\n",
    "        #IntermediateColumnNames.mask,\n",
    "        IntermediateColumnNames.total_mask\n",
    "    ]\n",
    "    images_kwargs = {}\n",
    "    for column in images_column_names:\n",
    "        images_kwargs[column] = row[column]\n",
    "\n",
    "    plot_images(n_columns=3, **images_kwargs)\n",
    "    \n",
    "    # Histograms\n",
    "    \n",
    "#     plot_hue_sat_val_histograms(row[IntermediateColumnNames.hue_histogram],\n",
    "#                                 row[IntermediateColumnNames.sat_histogram],\n",
    "#                                 row[IntermediateColumnNames.val_histogram],\n",
    "#                                 title='HSV Histogram')\n",
    "    \n",
    "    # Color masks\n",
    "    \n",
    "    images_column_names = [f'{col}_mask' for col in ColorPredictor.color_names]\n",
    "    images_column_names += [f'{col}_mask_full' for col in ColorPredictor.color_names]\n",
    "    images_kwargs = {}\n",
    "    for column in images_column_names:\n",
    "        images_kwargs[column] = row[column]\n",
    "        \n",
    "    \n",
    "    plot_images(n_columns=6, **images_kwargs)\n",
    "\n",
    "\n",
    "widgets.interact(showcase_mislabeling, index=file_slider_mitakes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search color HSV weight\n",
    "\n",
    "We can do the same for the other hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_ones(): \n",
    "    hsv_color_weights = {}\n",
    "    for color in ColorPredictor.color_names:\n",
    "        hsv_color_weights[color] = (1,1,1)\n",
    "    return hsv_color_weights\n",
    "\n",
    "def normalize_hsv_color_weights(hsv_color_weights):\n",
    "    for color_Name in hsv_color_weights.keys():\n",
    "        # Calculate the square root of the sum of squares of elements\n",
    "        arr = np.array(hsv_color_weights[color_Name])\n",
    "        sum_of_squares = np.sum(arr**2)\n",
    "        sqrt_sum_of_squares = np.sqrt(sum_of_squares)\n",
    "\n",
    "        # Normalize the array\n",
    "        normalized_arr = arr / sqrt_sum_of_squares\n",
    "        hsv_color_weights[color_Name] = normalized_arr\n",
    "    return hsv_color_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for 'infer': 2.441002 seconds\n",
      "Execution time for 'infer': 2.473000 seconds\n",
      "Execution time for 'infer': 2.323000 seconds\n",
      "Execution time for 'infer': 2.377999 seconds\n",
      "Execution time for 'infer': 2.351000 seconds\n",
      "Execution time for 'infer': 2.302000 seconds\n",
      "Execution time for 'infer': 2.313998 seconds\n",
      "Execution time for 'infer': 2.509999 seconds\n",
      "Execution time for 'infer': 2.324000 seconds\n",
      "Execution time for 'infer': 2.323997 seconds\n",
      "Execution time for 'infer': 2.313000 seconds\n",
      "Execution time for 'infer': 2.302999 seconds\n",
      "Execution time for 'infer': 2.326000 seconds\n",
      "Execution time for 'infer': 2.314000 seconds\n",
      "Execution time for 'infer': 2.300001 seconds\n",
      "Execution time for 'infer': 2.290001 seconds\n",
      "Execution time for 'infer': 2.307000 seconds\n",
      "Execution time for 'infer': 2.314000 seconds\n",
      "Execution time for 'infer': 2.308998 seconds\n",
      "Execution time for 'infer': 2.315000 seconds\n",
      "Execution time for 'infer': 2.314000 seconds\n",
      "Execution time for 'infer': 2.295001 seconds\n",
      "Execution time for 'infer': 2.316999 seconds\n",
      "Execution time for 'infer': 2.303000 seconds\n",
      "Execution time for 'infer': 2.320999 seconds\n",
      "Execution time for 'infer': 2.333000 seconds\n",
      "Execution time for 'infer': 2.402000 seconds\n",
      "Execution time for 'infer': 2.294001 seconds\n",
      "Execution time for 'infer': 2.311996 seconds\n",
      "Execution time for 'infer': 2.297001 seconds\n",
      "Execution time for 'infer': 2.300999 seconds\n",
      "Execution time for 'infer': 2.339999 seconds\n",
      "Execution time for 'infer': 2.315000 seconds\n",
      "Execution time for 'infer': 2.313999 seconds\n",
      "Execution time for 'infer': 2.310984 seconds\n",
      "Execution time for 'infer': 2.293000 seconds\n",
      "Execution time for 'infer': 2.300000 seconds\n",
      "Execution time for 'infer': 2.299999 seconds\n",
      "Execution time for 'infer': 2.290999 seconds\n",
      "Execution time for 'infer': 2.291000 seconds\n",
      "Execution time for 'infer': 2.303999 seconds\n",
      "Execution time for 'infer': 2.296998 seconds\n",
      "Execution time for 'infer': 2.410006 seconds\n",
      "Execution time for 'infer': 2.313999 seconds\n",
      "Execution time for 'infer': 2.314000 seconds\n",
      "Execution time for 'infer': 2.304998 seconds\n",
      "Execution time for 'infer': 2.317000 seconds\n",
      "Execution time for 'infer': 2.298997 seconds\n",
      "Execution time for 'infer': 2.304000 seconds\n",
      "Execution time for 'infer': 2.330999 seconds\n",
      "Execution time for 'infer': 2.311000 seconds\n",
      "Execution time for 'infer': 2.302000 seconds\n",
      "Execution time for 'infer': 2.314001 seconds\n",
      "Execution time for 'infer': 2.325999 seconds\n",
      "Execution time for 'infer': 2.310000 seconds\n",
      "Execution time for 'infer': 2.297998 seconds\n",
      "Execution time for 'infer': 2.333997 seconds\n",
      "Execution time for 'infer': 2.313998 seconds\n",
      "Execution time for 'infer': 2.317000 seconds\n",
      "Execution time for 'infer': 2.319000 seconds\n",
      "Best weights (random search): {'black': array([1.2, 0.8, 1.2]), 'blue': array([0.8, 0.9, 1. ]), 'brown': array([1. , 1.1, 1.1]), 'green': array([0.8, 0.9, 1. ]), 'pink': array([1.1, 1. , 1. ]), 'red': array([1. , 0.9, 0.9]), 'silver': array([1. , 1.2, 0.9]), 'white': array([0.8, 0.9, 1.2]), 'yellow': array([0.8, 1.1, 1. ])}\n",
      "Best metric value: 0.8328064629434493\n"
     ]
    }
   ],
   "source": [
    "# from itertools import product\n",
    "\n",
    "# Define hyperparameter search space (within the range 0.8 to 1.2)\n",
    "search_space = np.linspace(0.8, 1.2, num=5)\n",
    "# print(search_space)\n",
    "\n",
    "# Initialize best metric and best weights\n",
    "best_overall_f1 = 0\n",
    "best_weights = None\n",
    "\n",
    "# Perform random search\n",
    "num_iterations = 2  # Adjust as needed\n",
    "for _ in range(num_iterations):\n",
    "    sampled_weights = {}\n",
    "    for color  in ColorPredictor.color_names:\n",
    "        sampled_weights[color] = np.random.choice(search_space, 3)\n",
    "        \n",
    "    # Normalize ?\n",
    "    #sampled_weights = normalize_hsv_color_weights(sampled_weights)\n",
    "        \n",
    "    ColorPredictor.hsv_color_weights = sampled_weights\n",
    "    df_temp = clr_predictor.infer()\n",
    "    eval_dfs, eval_dfs_names = clr_predictor.evaluate(df_temp, save_to_file=False)\n",
    "    overall_f1 = eval_dfs[3]['Overall'][-1]\n",
    "\n",
    "\n",
    "    # Update best metric and best weights if needed\n",
    "    if overall_f1 > best_overall_f1:\n",
    "        best_overall_f1 = overall_f1\n",
    "        best_weights = sampled_weights\n",
    "\n",
    "print(\"Best weights (random search):\", best_weights)\n",
    "print(\"Best metric value:\", best_overall_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for 'infer': 2.361999 seconds\n",
      "train_occupancy_scores.csv \n",
      " --------------------------------\n",
      "                 black  blue  brown  green  pink  red  silver  white  yellow  \\\n",
      "black              338    32      7      5     0    0      41      8       0   \n",
      "blue                23   384      0     31     0    0       5      0       0   \n",
      "brown               38     2    108      0     1   12       6      3       0   \n",
      "green               10     0      1    118     0    0       1      0      24   \n",
      "pink                25     3      3      1   297   66      10     19       0   \n",
      "red                 22     3      2      0     6  358       3      1       0   \n",
      "silver              27    13      8      2     0    0     127     39       1   \n",
      "white               20     2      9      1     0    0      72    205       1   \n",
      "yellow               9     0     75      0     0    0       2      3     214   \n",
      "Total Predicted    512   439    213    158   304  436     267    278     240   \n",
      "\n",
      "                 Total True  \n",
      "black                 431.0  \n",
      "blue                  443.0  \n",
      "brown                 170.0  \n",
      "green                 154.0  \n",
      "pink                  424.0  \n",
      "red                   395.0  \n",
      "silver                217.0  \n",
      "white                 310.0  \n",
      "yellow                303.0  \n",
      "Total Predicted         NaN  \n",
      "--------------------------------\n",
      "train_occupancy_scores.csv \n",
      " --------------------------------\n",
      "           Precision    Recall  F1-score  Overall\n",
      "black       0.660156  0.784223  0.716861      NaN\n",
      "blue        0.874715  0.866817  0.870748      NaN\n",
      "brown       0.507042  0.635294  0.563969      NaN\n",
      "green       0.746835  0.766234  0.756410      NaN\n",
      "pink        0.976974  0.700472  0.815934      NaN\n",
      "red         0.821101  0.906329  0.861613      NaN\n",
      "silver      0.475655  0.585253  0.524793      NaN\n",
      "white       0.737410  0.661290  0.697279      NaN\n",
      "yellow      0.891667  0.706271  0.788214      NaN\n",
      "Precision        NaN       NaN       NaN  0.75483\n",
      "Recall           NaN       NaN       NaN  0.75483\n",
      "F1-score         NaN       NaN       NaN  0.75483\n",
      "--------------------------------\n",
      "train_hist_conf_matrix.csv \n",
      " --------------------------------\n",
      "                 black  blue  brown  green  pink  red  silver  white  yellow  \\\n",
      "black              370     9      9      7     3    0      22     11       0   \n",
      "blue                23   407      1      7     2    1       0      1       1   \n",
      "brown               23     2     99      9    19    1       5      2      10   \n",
      "green                2     2      1    147     0    0       2      0       0   \n",
      "pink                 6     2      2      1   401    5       5      2       0   \n",
      "red                  1     1      1      0    62  330       0      0       0   \n",
      "silver              59    10      3      5     0    0      96     44       0   \n",
      "white               24     2      5     10     8    0      17    244       0   \n",
      "yellow               2    15      0      8     0    1       0      0     277   \n",
      "Total Predicted    510   450    121    194   495  338     147    304     288   \n",
      "\n",
      "                 Total True  \n",
      "black                 431.0  \n",
      "blue                  443.0  \n",
      "brown                 170.0  \n",
      "green                 154.0  \n",
      "pink                  424.0  \n",
      "red                   395.0  \n",
      "silver                217.0  \n",
      "white                 310.0  \n",
      "yellow                303.0  \n",
      "Total Predicted         NaN  \n",
      "--------------------------------\n",
      "train_hist_scores.csv \n",
      " --------------------------------\n",
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.725490  0.858469  0.786397       NaN\n",
      "blue        0.904444  0.918736  0.911534       NaN\n",
      "brown       0.818182  0.582353  0.680412       NaN\n",
      "green       0.757732  0.954545  0.844828       NaN\n",
      "pink        0.810101  0.945755  0.872688       NaN\n",
      "red         0.976331  0.835443  0.900409       NaN\n",
      "silver      0.653061  0.442396  0.527473       NaN\n",
      "white       0.802632  0.787097  0.794788       NaN\n",
      "yellow      0.961806  0.914191  0.937394       NaN\n",
      "Precision        NaN       NaN       NaN  0.832806\n",
      "Recall           NaN       NaN       NaN  0.832806\n",
      "F1-score         NaN       NaN       NaN  0.832806\n",
      "--------------------------------\n",
      "test_occupancy_scores.csv \n",
      " --------------------------------\n",
      "                 black  blue  brown  green  pink  red  silver  white  yellow  \\\n",
      "black               82     7      0      3     0    0       4      2       0   \n",
      "blue                 5    84      1      8     0    0       1      1       0   \n",
      "brown               13     1     17      0     0    3       3      3       0   \n",
      "green                1     0      0     29     0    0       0      0       5   \n",
      "pink                 6     2      3      1    83    4       0      1       0   \n",
      "red                  5     0      0      0     2   90       0      3       0   \n",
      "silver               3     1      5      1     0    0      21      9       0   \n",
      "white                7     2      0      0     0    0      15     25       0   \n",
      "yellow               0     0     22      0     0    0       0      1      77   \n",
      "Total Predicted    122    97     48     42    85   97      44     45      82   \n",
      "\n",
      "                 Total True  \n",
      "black                  98.0  \n",
      "blue                  100.0  \n",
      "brown                  40.0  \n",
      "green                  35.0  \n",
      "pink                  100.0  \n",
      "red                   100.0  \n",
      "silver                 40.0  \n",
      "white                  49.0  \n",
      "yellow                100.0  \n",
      "Total Predicted         NaN  \n",
      "--------------------------------\n",
      "test_occupancy_scores.csv \n",
      " --------------------------------\n",
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.672131  0.836735  0.745455       NaN\n",
      "blue        0.865979  0.840000  0.852792       NaN\n",
      "brown       0.354167  0.425000  0.386364       NaN\n",
      "green       0.690476  0.828571  0.753247       NaN\n",
      "pink        0.976471  0.830000  0.897297       NaN\n",
      "red         0.927835  0.900000  0.913706       NaN\n",
      "silver      0.477273  0.525000  0.500000       NaN\n",
      "white       0.555556  0.510204  0.531915       NaN\n",
      "yellow      0.939024  0.770000  0.846154       NaN\n",
      "Precision        NaN       NaN       NaN  0.767372\n",
      "Recall           NaN       NaN       NaN  0.767372\n",
      "F1-score         NaN       NaN       NaN  0.767372\n",
      "--------------------------------\n",
      "test_hist_conf_matrix.csv \n",
      " --------------------------------\n",
      "                 black  blue  brown  green  pink  red  silver  white  yellow  \\\n",
      "black               74     3      1      6     1    0      10      3       0   \n",
      "blue                 9    82      1      1     5    0       1      1       0   \n",
      "brown               11     1     17      0     4    2       4      0       1   \n",
      "green                4     2      1     27     1    0       0      0       0   \n",
      "pink                 3     1      4      0    87    3       2      0       0   \n",
      "red                  0     0      0      0    18   82       0      0       0   \n",
      "silver               6     1      2      2     0    0      12     17       0   \n",
      "white                6     1      0      1     1    1       7     31       1   \n",
      "yellow               0    10      0      7     0    0       0      1      82   \n",
      "Total Predicted    113   101     26     44   117   88      36     53      84   \n",
      "\n",
      "                 Total True  \n",
      "black                  98.0  \n",
      "blue                  100.0  \n",
      "brown                  40.0  \n",
      "green                  35.0  \n",
      "pink                  100.0  \n",
      "red                   100.0  \n",
      "silver                 40.0  \n",
      "white                  49.0  \n",
      "yellow                100.0  \n",
      "Total Predicted         NaN  \n",
      "--------------------------------\n",
      "test_hist_scores.csv \n",
      " --------------------------------\n",
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.654867  0.755102  0.701422       NaN\n",
      "blue        0.811881  0.820000  0.815920       NaN\n",
      "brown       0.653846  0.425000  0.515152       NaN\n",
      "green       0.613636  0.771429  0.683544       NaN\n",
      "pink        0.743590  0.870000  0.801843       NaN\n",
      "red         0.931818  0.820000  0.872340       NaN\n",
      "silver      0.333333  0.300000  0.315789       NaN\n",
      "white       0.584906  0.632653  0.607843       NaN\n",
      "yellow      0.976190  0.820000  0.891304       NaN\n",
      "Precision        NaN       NaN       NaN  0.746224\n",
      "Recall           NaN       NaN       NaN  0.746224\n",
      "F1-score         NaN       NaN       NaN  0.746224\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lets evaluate the new weights\n",
    "\n",
    "# best_weights =  {'black': array([1.2, 0.8, 1.2]), 'blue': array([0.8, 0.9, 1. ]),\n",
    "#                  'brown': array([1. , 1.1, 1.1]), 'green': array([0.8, 0.9, 1. ]),\n",
    "#                  'pink': array([1.1, 1. , 1. ]), 'red': array([1. , 0.9, 0.9]),\n",
    "#                  'silver': array([1. , 1.2, 0.9]), 'white': array([0.8, 0.9, 1.2]),\n",
    "#                  'yellow': array([0.8, 1.1, 1. ])}\n",
    "ColorPredictor.hsv_color_weights = best_weights\n",
    "\n",
    "df_temp = clr_predictor.infer(save_to_file=False)\n",
    "eval_dfs, eval_dfs_names = clr_predictor.evaluate(df_temp, save_to_file=False)\n",
    "#        old weights     new weights\n",
    "# train  809624         0.832806\n",
    "# test   722054         0.767372\n",
    "\n",
    "\n",
    "for eval_df, eval_df_name in zip(eval_dfs, eval_dfs_names):\n",
    "    print(eval_df_name, '\\n --------------------------------')\n",
    "    print(eval_df)\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try some machine learning stuff\n",
    "\n",
    "Now we transform the features with PCA or CFS and use those to train:\n",
    "logistic regression, SVM, RFC, KNN, NB, LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2847, 9)\n",
      "(2847,)\n",
      "(662, 9)\n",
      "(662,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from copy import deepcopy\n",
    "\n",
    "dist_columns_names = [f'{color}_dist' for color in ColorPredictor.color_names]\n",
    "occupancy_columns_names = [f'{color}_occupancy' for color in ColorPredictor.color_names]\n",
    "\n",
    "# TRy different combinations\n",
    "columns = occupancy_columns_names\n",
    "#columns = dist_columns_names \n",
    "#columns = occupancy_columns_names\n",
    "\n",
    "# Train set\n",
    "df_train = deepcopy(df_inferred[df_inferred['dataset'] == 'train'])\n",
    "X_train = np.array(df_train[columns])\n",
    "print(X_train.shape)\n",
    "#X_train = np.array(df[columns])\n",
    "#X_train[:, 0:9] = 20 / X_train[:, 0:9]\n",
    "\n",
    "y_train = np.array(df_train['true_color'])\n",
    "print(y_train.shape)\n",
    "\n",
    "# Train set\n",
    "df_test = deepcopy(df_inferred[df_inferred['dataset'] == 'test'])\n",
    "X_test = np.array(df_test[columns])\n",
    "print(X_test.shape)\n",
    "#X_train = np.array(df[columns])\n",
    "#X_train[:, 0:9] = 20 / X_train[:, 0:9]\n",
    "\n",
    "y_test = np.array(df_test['true_color'])\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "# Encode class labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Results\n",
    "\n",
    "#       F1 scores\n",
    "\n",
    "#  Raw scores from before\n",
    "#       histograms  Occupancy \n",
    "# Train  0.809624   0.75483\n",
    "# Test   0.722054   0.767372\n",
    "\n",
    "#       features = 9 = only occupancy\n",
    "#       logisticregr   RFC       SVM        KNN         NB          LDA \n",
    "# Train  0.809975      0.99      0.816649   0.834211    0.789603    0.791008\n",
    "# Test   0.811178      0.806647  0.817221   0.805136    0.797583    0.796073\n",
    "# max test score = 0.806\n",
    "\n",
    "#       features = 9 =only histograms\n",
    "#       logisticregr   RFC       SVM        KNN         NB          LDA \n",
    "# Train 0.855286       0.994731  0.874254   0.776256    0.525465    0.554619\n",
    "# Test  0.767372       0.750755  0.768882   0.714502    0.510574    0.515106\n",
    "# max test score = 0.768\n",
    "\n",
    "#       features = 18 = both\n",
    "#       logisticregr   RFC       SVM        KNN         NB          LDA \n",
    "# Train 0.855638       0.994731  0.874254   0.776256    0.761503    0.802248\n",
    "# Test  0.767372       0.809668  0.768882   0.714502    0.731118    0.802248\n",
    "# max test score = 0.809"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# Train CFS with encoded labels\n",
    "num_features = 9\n",
    "cfs_selector = SelectKBest(score_func=f_classif, k=num_features)\n",
    "X_train_cfs = cfs_selector.fit_transform(X_train, y_train_encoded)\n",
    "\n",
    "X_test_cfs = cfs_selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Train PCA with encoded labels\n",
    "num_components = 9\n",
    "pca = PCA(n_components=num_components)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.744235  0.823666  0.781938       NaN\n",
      "blue        0.902004  0.914221  0.908072       NaN\n",
      "brown       0.658960  0.670588  0.664723       NaN\n",
      "green       0.848276  0.798701  0.822742       NaN\n",
      "pink        0.933518  0.794811  0.858599       NaN\n",
      "red         0.838710  0.921519  0.878166       NaN\n",
      "silver      0.526882  0.451613  0.486352       NaN\n",
      "white       0.743827  0.777419  0.760252       NaN\n",
      "yellow      0.902685  0.887789  0.895175       NaN\n",
      "Precision        NaN       NaN       NaN  0.809975\n",
      "Recall           NaN       NaN       NaN  0.809975\n",
      "F1-score         NaN       NaN       NaN  0.809975\n",
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.735043  0.877551  0.800000       NaN\n",
      "blue        0.876289  0.850000  0.862944       NaN\n",
      "brown       0.666667  0.400000  0.500000       NaN\n",
      "green       0.736842  0.800000  0.767123       NaN\n",
      "pink        0.900990  0.910000  0.905473       NaN\n",
      "red         0.936170  0.880000  0.907216       NaN\n",
      "silver      0.435897  0.425000  0.430380       NaN\n",
      "white       0.612245  0.612245  0.612245       NaN\n",
      "yellow      0.932039  0.960000  0.945813       NaN\n",
      "Precision        NaN       NaN       NaN  0.811178\n",
      "Recall           NaN       NaN       NaN  0.811178\n",
      "F1-score         NaN       NaN       NaN  0.811178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Assume you have already performed PCA and CFS\n",
    "# X_train_pca, X_test_pca: Reduced features after PCA\n",
    "# X_train_cfs, X_test_cfs: Reduced features after CFS\n",
    "\n",
    "# Create a pipeline with PCA and logistic regression\n",
    "pca = PCA(n_components=9)  # Adjust the number of components\n",
    "clf = LogisticRegression()\n",
    "\n",
    "pipe_pca = Pipeline([('pca', pca), ('logistic', clf)])\n",
    "pipe_pca.fit(X_train_pca, y_train)\n",
    "#pipe_pca.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predictions on train set\n",
    "train_predictions_pca = pipe_pca.predict(X_train_pca)\n",
    "#train_predictions_pca = pipe_pca.predict(X_train)\n",
    "\n",
    "df_train['pred_pca_log_label'] = train_predictions_pca\n",
    "print(create_evaluation_df(df_train,'true_color', 'pred_pca_log_label'))\n",
    "\n",
    "# Predictions on test set\n",
    "test_predictions_pca = pipe_pca.predict(X_test_pca)\n",
    "#test_predictions_pca = pipe_pca.predict(X_test)\n",
    "df_test['pred_pca_log_label'] = test_predictions_pca\n",
    "print(create_evaluation_df(df_test,'true_color', 'pred_pca_log_label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.988453  0.993039  0.990741       NaN\n",
      "blue        0.995485  0.995485  0.995485       NaN\n",
      "brown       1.000000  0.988235  0.994083       NaN\n",
      "green       0.993548  1.000000  0.996764       NaN\n",
      "pink        0.995294  0.997642  0.996466       NaN\n",
      "red         0.997468  0.997468  0.997468       NaN\n",
      "silver      0.986175  0.986175  0.986175       NaN\n",
      "white       0.996753  0.990323  0.993528       NaN\n",
      "yellow      1.000000  1.000000  1.000000       NaN\n",
      "Precision        NaN       NaN       NaN  0.994731\n",
      "Recall           NaN       NaN       NaN  0.994731\n",
      "F1-score         NaN       NaN       NaN  0.994731\n",
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.690265  0.795918  0.739336       NaN\n",
      "blue        0.893617  0.840000  0.865979       NaN\n",
      "brown       0.677419  0.525000  0.591549       NaN\n",
      "green       0.896552  0.742857  0.812500       NaN\n",
      "pink        0.894231  0.930000  0.911765       NaN\n",
      "red         0.967391  0.890000  0.927083       NaN\n",
      "silver      0.387755  0.475000  0.426966       NaN\n",
      "white       0.592593  0.653061  0.621359       NaN\n",
      "yellow      0.979167  0.940000  0.959184       NaN\n",
      "Precision        NaN       NaN       NaN  0.809668\n",
      "Recall           NaN       NaN       NaN  0.809668\n",
      "F1-score         NaN       NaN       NaN  0.809668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=10)  # Adjust hyperparameters\n",
    "\n",
    "# Fit the model on reduced features, or raw features\n",
    "rf.fit(X_train, y_train)\n",
    "#rf.fit(X_train_pca, y_train)\n",
    "#rf.fit(X_train_cfs, y_train)\n",
    "\n",
    "# Predictions on train set\n",
    "train_predictions_cfs_rf = rf.predict(X_train_cfs)\n",
    "df_train['pred_rf_label'] = train_predictions_cfs_rf\n",
    "print(create_evaluation_df(df_train,'true_color', 'pred_rf_label'))\n",
    "\n",
    "# Predictions on test set\n",
    "test_predictions_cfs_rf = rf.predict(X_test_cfs)\n",
    "df_test['pred_rf_label'] = test_predictions_cfs_rf\n",
    "print(create_evaluation_df(df_test,'true_color', 'pred_rf_label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.771008  0.851508  0.809261       NaN\n",
      "blue        0.947005  0.927765  0.937286       NaN\n",
      "brown       0.804734  0.800000  0.802360       NaN\n",
      "green       0.940789  0.928571  0.934641       NaN\n",
      "pink        0.931707  0.900943  0.916067       NaN\n",
      "red         0.946565  0.941772  0.944162       NaN\n",
      "silver      0.634615  0.608295  0.621176       NaN\n",
      "white       0.831126  0.809677  0.820261       NaN\n",
      "yellow      0.973597  0.973597  0.973597       NaN\n",
      "Precision        NaN       NaN       NaN  0.874254\n",
      "Recall           NaN       NaN       NaN  0.874254\n",
      "F1-score         NaN       NaN       NaN  0.874254\n",
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.678571  0.775510  0.723810       NaN\n",
      "blue        0.836735  0.820000  0.828283       NaN\n",
      "brown       0.588235  0.500000  0.540541       NaN\n",
      "green       0.827586  0.685714  0.750000       NaN\n",
      "pink        0.807692  0.840000  0.823529       NaN\n",
      "red         0.946237  0.880000  0.911917       NaN\n",
      "silver      0.357143  0.375000  0.365854       NaN\n",
      "white       0.535714  0.612245  0.571429       NaN\n",
      "yellow      0.957447  0.900000  0.927835       NaN\n",
      "Precision        NaN       NaN       NaN  0.768882\n",
      "Recall           NaN       NaN       NaN  0.768882\n",
      "F1-score         NaN       NaN       NaN  0.768882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm = SVC(kernel='linear')  # Use linear kernel for simplicity\n",
    "\n",
    "# Fit the model on reduced features\n",
    "svm.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predictions on test set\n",
    "train_predictions_pca_svm = svm.predict(X_train_pca)\n",
    "df_train['pred_pca_svm_label'] = train_predictions_pca_svm\n",
    "print(create_evaluation_df(df_train,'true_color', 'pred_pca_svm_label'))\n",
    "\n",
    "# Predictions on test set\n",
    "test_predictions_pca_svm = svm.predict(X_test_pca)\n",
    "df_test['pred_pca_svm_label'] = test_predictions_pca_svm\n",
    "print(create_evaluation_df(df_test,'true_color', 'pred_pca_svm_label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.611615  0.781903  0.686354       NaN\n",
      "blue        0.833698  0.860045  0.846667       NaN\n",
      "brown       0.769231  0.588235  0.666667       NaN\n",
      "green       0.863014  0.818182  0.840000       NaN\n",
      "pink        0.828829  0.867925  0.847926       NaN\n",
      "red         0.900000  0.911392  0.905660       NaN\n",
      "silver      0.506494  0.359447  0.420485       NaN\n",
      "white       0.732852  0.654839  0.691652       NaN\n",
      "yellow      0.892361  0.848185  0.869712       NaN\n",
      "Precision        NaN       NaN       NaN  0.776256\n",
      "Recall           NaN       NaN       NaN  0.776256\n",
      "F1-score         NaN       NaN       NaN  0.776256\n",
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.492857  0.704082  0.579832       NaN\n",
      "blue        0.766990  0.790000  0.778325       NaN\n",
      "brown       0.542857  0.475000  0.506667       NaN\n",
      "green       0.724138  0.600000  0.656250       NaN\n",
      "pink        0.806122  0.790000  0.797980       NaN\n",
      "red         0.900990  0.910000  0.905473       NaN\n",
      "silver      0.347826  0.200000  0.253968       NaN\n",
      "white       0.512821  0.408163  0.454545       NaN\n",
      "yellow      0.925532  0.870000  0.896907       NaN\n",
      "Precision        NaN       NaN       NaN  0.714502\n",
      "Recall           NaN       NaN       NaN  0.714502\n",
      "F1-score         NaN       NaN       NaN  0.714502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create a k-NN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)  # Adjust the number of neighbors\n",
    "\n",
    "# Fit the model on reduced features\n",
    "knn.fit(X_train_cfs, y_train)\n",
    "#knn.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predictions on train set\n",
    "train_predictions_cfs_knn = knn.predict(X_train_cfs)\n",
    "#train_predictions_cfs_knn = knn.predict(X_train_pca)\n",
    "\n",
    "df_train['pred_cfs_knn_label'] = train_predictions_cfs_knn\n",
    "print(create_evaluation_df(df_train, 'true_color', 'pred_cfs_knn_label'))\n",
    "\n",
    "# Predictions on test set\n",
    "test_predictions_cfs_knn = knn.predict(X_test_cfs)\n",
    "#test_predictions_cfs_knn = knn.predict(X_test_pca)\n",
    "\n",
    "df_test['pred_cfs_knn_label'] = test_predictions_cfs_knn\n",
    "print(create_evaluation_df(df_test, 'true_color', 'pred_cfs_knn_label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.895349  0.357309  0.510779       NaN\n",
      "blue        0.929864  0.927765  0.928814       NaN\n",
      "brown       0.391645  0.882353  0.542495       NaN\n",
      "green       0.877419  0.883117  0.880259       NaN\n",
      "pink        0.919897  0.839623  0.877928       NaN\n",
      "red         0.880196  0.911392  0.895522       NaN\n",
      "silver      0.400000  0.221198  0.284866       NaN\n",
      "white       0.557692  0.841935  0.670951       NaN\n",
      "yellow      0.938907  0.963696  0.951140       NaN\n",
      "Precision        NaN       NaN       NaN  0.761503\n",
      "Recall           NaN       NaN       NaN  0.761503\n",
      "F1-score         NaN       NaN       NaN  0.761503\n",
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.735294  0.255102  0.378788       NaN\n",
      "blue        0.870968  0.810000  0.839378       NaN\n",
      "brown       0.314607  0.700000  0.434109       NaN\n",
      "green       0.736842  0.800000  0.767123       NaN\n",
      "pink        0.871287  0.880000  0.875622       NaN\n",
      "red         0.946809  0.890000  0.917526       NaN\n",
      "silver      0.241379  0.175000  0.202899       NaN\n",
      "white       0.475610  0.795918  0.595420       NaN\n",
      "yellow      0.970588  0.990000  0.980198       NaN\n",
      "Precision        NaN       NaN       NaN  0.731118\n",
      "Recall           NaN       NaN       NaN  0.731118\n",
      "F1-score         NaN       NaN       NaN  0.731118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Does worse with less columns features\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Fit the model on reduced features\n",
    "nb.fit(X_train_cfs, y_train)\n",
    "\n",
    "# Predictions on train set\n",
    "predictions_cfs_nb = nb.predict(X_train_cfs)\n",
    "df_train['pred_cfs_nb_label'] = predictions_cfs_nb\n",
    "print(create_evaluation_df(df_train, 'true_color', 'pred_cfs_nb_label'))\n",
    "\n",
    "# Predictions on test set\n",
    "predictions_cfs_nb = nb.predict(X_test_cfs)\n",
    "df_test['pred_cfs_nb_label'] = predictions_cfs_nb\n",
    "print(create_evaluation_df(df_test,'true_color', 'pred_cfs_nb_label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.775982  0.779582  0.777778       NaN\n",
      "blue        0.925234  0.893905  0.909300       NaN\n",
      "brown       0.576037  0.735294  0.645995       NaN\n",
      "green       0.787500  0.818182  0.802548       NaN\n",
      "pink        0.970238  0.768868  0.857895       NaN\n",
      "red         0.835214  0.936709  0.883055       NaN\n",
      "silver      0.475862  0.635945  0.544379       NaN\n",
      "white       0.809886  0.687097  0.743455       NaN\n",
      "yellow      0.916968  0.838284  0.875862       NaN\n",
      "Precision        NaN       NaN       NaN  0.802248\n",
      "Recall           NaN       NaN       NaN  0.802248\n",
      "F1-score         NaN       NaN       NaN  0.802248\n",
      "           Precision    Recall  F1-score   Overall\n",
      "black       0.761905  0.816327  0.788177       NaN\n",
      "blue        0.891304  0.820000  0.854167       NaN\n",
      "brown       0.538462  0.525000  0.531646       NaN\n",
      "green       0.714286  0.857143  0.779221       NaN\n",
      "pink        0.956044  0.870000  0.910995       NaN\n",
      "red         0.937500  0.900000  0.918367       NaN\n",
      "silver      0.392857  0.550000  0.458333       NaN\n",
      "white       0.622222  0.571429  0.595745       NaN\n",
      "yellow      0.937500  0.900000  0.918367       NaN\n",
      "Precision        NaN       NaN       NaN  0.800604\n",
      "Recall           NaN       NaN       NaN  0.800604\n",
      "F1-score         NaN       NaN       NaN  0.800604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Create an LDA classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Fit the model on reduced features\n",
    "lda.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predictions on test set\n",
    "predictions_pca_lda = lda.predict(X_train_pca)\n",
    "df_train['pred_pca_lda_label'] = predictions_pca_lda\n",
    "print(create_evaluation_df(df_train,'true_color', 'pred_pca_lda_label'))\n",
    "\n",
    "# Predictions on test set\n",
    "predictions_pca_lda = lda.predict(X_test_pca)\n",
    "df_test['pred_pca_lda_label'] = predictions_pca_lda\n",
    "print(create_evaluation_df(df_test,'true_color', 'pred_pca_lda_label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
